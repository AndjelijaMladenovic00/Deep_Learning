{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from keras.layers import Conv2D,Conv2DTranspose,BatchNormalization,LeakyReLU,Input,concatenate,Dropout,UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gray = 'dataset/gray/'\n",
    "path_color = 'dataset/color/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortiranje dobijenih podataka\n",
    "def sort_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
    "    return sorted(data,key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, color_path, gray_path, batch_size, image_size, image_names, pipeline = None, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.color_path = color_path\n",
    "        self.grayscale_path = gray_path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.image_names = image_names\n",
    "        self.shuffle = shuffle\n",
    "        self.pipeline = pipeline\n",
    "        self.indexes = np.arange(len(self.image_names))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_color_images = []\n",
    "        batch_gray_images = []\n",
    "\n",
    "        for i in indexes:\n",
    "            rgb_image = cv2.imread(os.path.join(self.color_path, self.image_names[i]))\n",
    "            rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "            rgb_image = cv2.resize(rgb_image, (self.image_size, self.image_size))\n",
    "            rgb_image = rgb_image.astype(\"float32\") / 255.0\n",
    "            batch_color_images.append(img_to_array(rgb_image))\n",
    "\n",
    "            grayscale_image = cv2.imread(os.path.join(self.grayscale_path, self.image_names[i]), cv2.IMREAD_GRAYSCALE)\n",
    "            grayscale_image = cv2.resize(grayscale_image, (self.image_size, self.image_size))\n",
    "            grayscale_image = grayscale_image.astype(\"float32\") / 255.0\n",
    "            grayscale_image = np.expand_dims(grayscale_image, axis=-1)\n",
    "            batch_gray_images.append(grayscale_image)\n",
    "        \n",
    "        batch_color_images = np.array(batch_color_images)\n",
    "        batch_gray_images = np.array(batch_gray_images)\n",
    "\n",
    "        if self.pipeline is not None:\n",
    "            batch_color_images, batch_gray_images = self.augment_images(batch_color_images, batch_gray_images)   \n",
    "\n",
    "        return batch_gray_images, batch_color_images\n",
    "    \n",
    "    def augment_images(self, color_images, gray_images):\n",
    "        # Apply augmentations to color and grayscale images\n",
    "        aug_color_images = self.pipeline(images=color_images)\n",
    "        aug_gray_images = self.pipeline(images=gray_images)\n",
    "        return aug_color_images, aug_gray_images\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_names))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the augmentation pipeline\n",
    "pipeline = iaa.Sequential([\n",
    "    iaa.Rot90((1, 3)),  # randomly rotate image from 90, 180, 270 degrees\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podela podataka na trening i test skup podataka i pravljenje generatora podataka.\n",
    "image_names = sort_alphanumeric(os.listdir(path_color))\n",
    "TRAINING_SIZE = int(len(image_names) * 0.8)\n",
    "train_image_names = image_names[:TRAINING_SIZE]\n",
    "test_image_names = image_names[TRAINING_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(path_color,path_gray,32,256,train_image_names,pipeline)\n",
    "test_generator = DataGenerator(path_color,path_gray,8,256,test_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up(filters, kernel_size, dropout=False):\n",
    "    upsample = Sequential()\n",
    "    upsample.add(Conv2DTranspose(filters, kernel_size, padding='same', strides=2))\n",
    "    if dropout:\n",
    "        upsample.add(Dropout(0.2))\n",
    "    upsample.add(LeakyReLU())\n",
    "    return upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down(filters, kernel_size, apply_batch_normalization=True):\n",
    "    downsample = Sequential()\n",
    "    downsample.add(Conv2D(filters, kernel_size, padding='same', strides=2))\n",
    "    if apply_batch_normalization:\n",
    "        downsample.add(BatchNormalization())\n",
    "    downsample.add(LeakyReLU())\n",
    "    return downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder():\n",
    "    inputs = Input(shape= [256,256,1])\n",
    "    d1 = down(128,(3,3),False)(inputs)\n",
    "    d2 = down(128,(3,3),False)(d1)\n",
    "    d3 = down(256,(3,3),True)(d2)\n",
    "    d4 = down(512,(3,3),True)(d3)\n",
    "    \n",
    "    d5 = down(512,(3,3),True)(d4)\n",
    "    #upsampling\n",
    "    u1 = up(512,(3,3),False)(d5)\n",
    "    u1 = concatenate([u1,d4])\n",
    "    u2 = up(256,(3,3),False)(u1)\n",
    "    u2 = concatenate([u2,d3])\n",
    "    u3 = up(128,(3,3),False)(u2)\n",
    "    u3 = concatenate([u3,d2])\n",
    "    u4 = up(128,(3,3),False)(u3)\n",
    "    u4 = concatenate([u4,d1])\n",
    "    u5 = up(3,(3,3),False)(u4)\n",
    "    u5 = concatenate([u5,inputs])\n",
    "    output = Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 128, 128, 128)        1280      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 64, 64, 128)          147584    ['sequential[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)   (None, 32, 32, 256)          296192    ['sequential_1[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)   (None, 16, 16, 512)          1182208   ['sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_4 (Sequential)   (None, 8, 8, 512)            2361856   ['sequential_3[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_5 (Sequential)   (None, 16, 16, 512)          2359808   ['sequential_4[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 1024)         0         ['sequential_5[0][0]',        \n",
      "                                                                     'sequential_3[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_6 (Sequential)   (None, 32, 32, 256)          2359552   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 32, 32, 512)          0         ['sequential_6[0][0]',        \n",
      " )                                                                   'sequential_2[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_7 (Sequential)   (None, 64, 64, 128)          589952    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 64, 256)          0         ['sequential_7[0][0]',        \n",
      " )                                                                   'sequential_1[0][0]']        \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)   (None, 128, 128, 128)        295040    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 256)        0         ['sequential_8[0][0]',        \n",
      " )                                                                   'sequential[0][0]']          \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)   (None, 256, 256, 3)          6915      ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 256, 256, 4)          0         ['sequential_9[0][0]',        \n",
      " )                                                                   'input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 256, 256, 3)          51        ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9600438 (36.62 MB)\n",
      "Trainable params: 9597878 (36.61 MB)\n",
      "Non-trainable params: 2560 (10.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the model\n",
    "autoencoder = build_autoencoder()\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_absolute_error', metrics=['accuracy'])\n",
    "\n",
    "# Check the model summary to see the tensor shapes\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "178/178 [==============================] - 4139s 23s/step - loss: 0.2135 - accuracy: 0.3456 - val_loss: 0.1468 - val_accuracy: 0.4031\n",
      "Epoch 2/30\n",
      "178/178 [==============================] - 3821s 21s/step - loss: 0.2026 - accuracy: 0.3708 - val_loss: 0.1572 - val_accuracy: 0.4361\n",
      "Epoch 3/30\n",
      "178/178 [==============================] - 3556s 20s/step - loss: 0.2015 - accuracy: 0.3865 - val_loss: 0.1773 - val_accuracy: 0.3685\n",
      "Epoch 4/30\n",
      "178/178 [==============================] - 3755s 21s/step - loss: 0.1997 - accuracy: 0.3880 - val_loss: 0.1515 - val_accuracy: 0.4583\n",
      "Epoch 5/30\n",
      "178/178 [==============================] - 3554s 20s/step - loss: 0.2008 - accuracy: 0.3943 - val_loss: 0.1676 - val_accuracy: 0.3293\n",
      "Epoch 6/30\n",
      "178/178 [==============================] - 3598s 20s/step - loss: 0.2004 - accuracy: 0.3967 - val_loss: 0.1778 - val_accuracy: 0.2869\n",
      "Epoch 7/30\n",
      "178/178 [==============================] - 3586s 20s/step - loss: 0.1994 - accuracy: 0.4063 - val_loss: 0.1524 - val_accuracy: 0.4710\n",
      "Epoch 8/30\n",
      "  3/178 [..............................] - ETA: 58:14 - loss: 0.1973 - accuracy: 0.4149"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train_generator, validation_data=test_generator, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 79s 442ms/step - loss: 0.0543 - accuracy: 0.4236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05431590601801872, 0.42359164357185364]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(model, test_generator, num_examples=5):\n",
    "    count = 0\n",
    "    for batch in test_generator:\n",
    "        if count >= num_examples:\n",
    "            break\n",
    "        grayscale_images, rgb_images = batch\n",
    "        predictions = model.predict(grayscale_images)\n",
    "        for i in range(len(grayscale_images)):\n",
    "            input_image = grayscale_images[i]\n",
    "            target_image = rgb_images[i]\n",
    "            predicted_image = predictions[i]\n",
    "            display_list = [input_image, target_image, predicted_image]\n",
    "            title = [\"Input (Grayscale)\", \"Ground Truth (Color)\", \"Predicted (Color)\"]\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            for j in range(3):\n",
    "                plt.subplot(1, 3, j + 1)\n",
    "                plt.title(title[j])\n",
    "                if j == 0:  # Grayscale image\n",
    "                    plt.imshow(display_list[j], cmap='gray')\n",
    "                else:\n",
    "                    plt.imshow(display_list[j])\n",
    "                plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            count += 1\n",
    "            if count >= num_examples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 388ms/step\n"
     ]
    }
   ],
   "source": [
    "gray_images, color_images = next(iter(test_generator))\n",
    "\n",
    "# Predict the colorized images\n",
    "predicted_color_images = autoencoder.predict(gray_images)\n",
    "\n",
    "# # Denormalize images for visualization\n",
    "# gray_images = (gray_images * 255).astype(\"uint8\")\n",
    "# color_images = (color_images * 255).astype(\"uint8\")\n",
    "predicted_color_images = (predicted_color_images * 255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prikaz rezultata.\n",
    "generate_examples(autoencoder, test_generator, num_examples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
