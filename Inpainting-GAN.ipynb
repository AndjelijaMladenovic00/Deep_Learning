{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c99d78-d6cc-48be-b227-0b0d130920c2",
   "metadata": {},
   "source": [
    "# Inpainting using GAN-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1218eb2-8bcb-4353-8214-543814bc94a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andje\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b3fba7-7c6a-4533-a4dd-740df53c30b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████▍           | 3969/7129 [00:57<00:45, 68.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\PROGRA~1\\KMSpico\\temp/ipykernel_13908/2847739748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mrgb_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgrayscale_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayscale_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mgrayscale_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayscale_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mgrayscale_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayscale_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Učitavanje svih slika, resize-ovanje na veličinu 255x255 i konvertovanje vrednosti u opseg [0, 1]\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "rgb_path = \"dataset/color/\"\n",
    "grayscale_path = \"dataset/gray/\"\n",
    "rgb_images = []\n",
    "grayscale_images = []\n",
    "\n",
    "image_names = os.listdir(rgb_path)\n",
    "image_names = sorted(image_names, key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "for image_name in tqdm(image_names):\n",
    "    rgb_image = cv.imread(rgb_path + image_name)\n",
    "    rgb_image = cv.cvtColor(rgb_image, cv.COLOR_BGR2RGB)\n",
    "    rgb_image = cv.resize(rgb_image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    rgb_image = rgb_image.astype(\"float32\") / 255.0\n",
    "    rgb_images.append(img_to_array(rgb_image))\n",
    "\n",
    "    grayscale_image = cv.imread(grayscale_path + image_name)\n",
    "    grayscale_image = cv.cvtColor(grayscale_image, cv.COLOR_BGR2RGB)\n",
    "    grayscale_image = cv.resize(grayscale_image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    grayscale_image = grayscale_image.astype(\"float32\") / 255.0\n",
    "    grayscale_images.append(img_to_array(grayscale_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8f2a2-22d9-4f22-84b2-cbd2a2116e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podela podataka na trening i test setove. \n",
    "TRAINING_SIZE = int(len(image_names) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57a5482-4df9-484b-9107-6e42b402e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train_set = tf.data.Dataset.from_tensor_slices(rgb_images[:TRAINING_SIZE]).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f6415-4332-43a3-8142-d7f47781da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_test_set = tf.data.Dataset.from_tensor_slices(rgb_images[TRAINING_SIZE:]).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c51791-3776-4ef8-9a12-bb9deee97538",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_train_set = tf.data.Dataset.from_tensor_slices(grayscale_images[:TRAINING_SIZE]).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09eae9-dfa5-4b81-ac35-0423b149396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_test_set = tf.data.Dataset.from_tensor_slices(grayscale_images[TRAINING_SIZE:]).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578ac62-2819-4c6b-b04a-5c58e8fceb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje funkcija za dodavanje slojeva mreži.\n",
    "def add_downsampling_layer(filters, size, normalize=True):\n",
    "    layers = tf.keras.Sequential()\n",
    "    layers.add(tf.keras.layers.Conv2D(filters, \n",
    "                                      size, \n",
    "                                      strides=2, \n",
    "                                      padding=\"same\",\n",
    "                                      kernel_initializer=\"he_normal\",\n",
    "                                      use_bias=False))\n",
    "    if normalize:\n",
    "        layers.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    layers.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de18b5e-d55b-428c-897a-ec6f7c198d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_upsampling_layer(filters, size, dropout=False):\n",
    "    layers = tf.keras.Sequential()\n",
    "    layers.add(tf.keras.layers.Conv2DTranspose(filters, \n",
    "                                      size, \n",
    "                                      strides=2, \n",
    "                                      padding=\"same\",\n",
    "                                      kernel_initializer=\"he_normal\",\n",
    "                                      use_bias=False))\n",
    "    \n",
    "    layers.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    if dropout:\n",
    "        layers.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "    layers.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006615c-371d-4b9d-9cee-ad85bf021ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje Generator mreže.\n",
    "def make_generator():\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "    downsampling_layers = [\n",
    "        add_downsampling_layer(64, 4, normalize=False),\n",
    "        add_downsampling_layer(128, 4),\n",
    "        add_downsampling_layer(256, 4),\n",
    "        add_downsampling_layer(512, 4),\n",
    "        add_downsampling_layer(512, 4),\n",
    "        add_downsampling_layer(512, 4),\n",
    "        add_downsampling_layer(512, 4),\n",
    "        add_downsampling_layer(512, 4),\n",
    "    ]\n",
    "\n",
    "    upsampling_layers = [\n",
    "        add_upsampling_layer(512, 4, dropout=True),\n",
    "        add_upsampling_layer(512, 4, dropout=True),\n",
    "        add_upsampling_layer(512, 4, dropout=True),\n",
    "        add_upsampling_layer(512, 4),\n",
    "        add_upsampling_layer(256, 4),\n",
    "        add_upsampling_layer(128, 4),\n",
    "        add_upsampling_layer(64, 4),\n",
    "    ]\n",
    "\n",
    "    last_layer = tf.keras.layers.Conv2DTranspose(3, \n",
    "                                                 4,\n",
    "                                                 strides=2,\n",
    "                                                 padding=\"same\",\n",
    "                                                 kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                                                 activation=\"tanh\")\n",
    "    x = inputs\n",
    "    downsampled = []\n",
    "\n",
    "    for layer in downsampling_layers:\n",
    "        x = layer(x)\n",
    "        downsampled.append(x)\n",
    "\n",
    "    downsampled = downsampled[:-1][::-1]\n",
    "\n",
    "    for i in range(len(upsampling_layers)):\n",
    "        x = upsampling_layers[i](x)\n",
    "        x = tf.keras.layers.Concatenate()([x, downsampled[i]])\n",
    "\n",
    "    x = last_layer(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9748c8a-310e-496f-b75e-921f48d2d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje Diskriminator mreže.\n",
    "def make_discriminator():\n",
    "    image = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], name=\"image\")\n",
    "    target = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], name=\"target\")\n",
    "\n",
    "    inputs = tf.keras.layers.concatenate([image, target])\n",
    "\n",
    "    downsampled1 = add_downsampling_layer(64, 4, False)(inputs)\n",
    "    downsampled2 = add_downsampling_layer(128, 4)(downsampled1)\n",
    "    downsampled3 = add_downsampling_layer(256, 4)(downsampled2)\n",
    "\n",
    "    padding = tf.keras.layers.ZeroPadding2D()(downsampled3)    \n",
    "\n",
    "    convolution = tf.keras.layers.Conv2D(512,\n",
    "                                         4,\n",
    "                                         strides=1,\n",
    "                                         kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                                         use_bias=False)(padding)\n",
    "\n",
    "    normalization = tf.keras.layers.BatchNormalization()(convolution)\n",
    "    activation = tf.keras.layers.LeakyReLU()(normalization)\n",
    "    padding2 = tf.keras.layers.ZeroPadding2D()(activation)\n",
    "    final = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=tf.random_normal_initializer(0., 0.02))(padding2)\n",
    "\n",
    "    return tf.keras.Model(inputs=[image, target], outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716f3bc-0db5-4d2b-81d4-63ca6b74d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje loss funkcija.\n",
    "losses = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "LAMBDA = 100\n",
    "\n",
    "def generator_loss(disc_output, gen_output, target):\n",
    "    gan_loss = losses(tf.ones_like(disc_output), disc_output)\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    gen_loss = gan_loss + LAMBDA * l1_loss\n",
    "\n",
    "    return gen_loss, gan_loss, l1_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(real, generated):\n",
    "    real_loss = losses(tf.ones_like(real), real)\n",
    "    generated_loss = losses(tf.zeros_like(generated), generated)\n",
    "    disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f96d7-dc5f-46ef-aef5-7105cada2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje treninga.\n",
    "generator = make_generator()\n",
    "discriminator = make_discriminator()\n",
    "\n",
    "gen_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "def training_step(image, target, epoch): #epoha se ne koristi\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator(image, training=True)\n",
    "        disc_real_output = discriminator([image, target], training=True)\n",
    "        disc_generated_output = discriminator([image, gen_output], training=True)\n",
    "\n",
    "        gen_loss, gan_loss, l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "        gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
    "        disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1cca6-ed1c-4b1d-83d3-ce10b10d5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisanje fit funkcije.\n",
    "def fit(train_dataset, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        print(\"Epoch: \", epoch + 1)\n",
    "\n",
    "        for n, (input_image, target) in train_dataset.enumerate():\n",
    "            training_step(input_image, target, epoch)\n",
    "            \n",
    "        print (f\"Time taken for epoch {epoch + 1} is {time.time() - start_time} sec\\n\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7409fab-8bbe-49e9-afb0-0618ab8d2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(tf.data.Dataset.zip((grayscale_train_set, rgb_train_set)), num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07323d-0ea1-4db9-9a68-643796fd01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.compile(loss=\"MSE\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Definisanje testiranja.\n",
    "def test_and_evaluate(grayscale_test_dataset, rgb_test_dataset):\n",
    "    print(grayscale_test_dataset.cardinality().numpy())\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    num_data = grayscale_test_dataset.cardinality().numpy()\n",
    "    \n",
    "    for input, target in tqdm(tf.data.Dataset.zip((grayscale_test_dataset, rgb_test_dataset))):\n",
    "        loss, accuracy = generator.evaluate(input, target)\n",
    "        average_loss += loss\n",
    "        average_accuracy += accuracy\n",
    "\n",
    "    average_loss /= num_data\n",
    "    average_accuracy /= num_data\n",
    "\n",
    "    return average_loss, average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5648ac5e-ae56-4526-9568-4946115ae5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_loss, average_accuracy = test_and_evaluate(grayscale_test_set, rgb_test_set)\n",
    "print(f\"Average loss: {average_loss}\")\n",
    "print(f\"Average accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72cd2c-fbcd-4438-ae06-da8b629ae2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generisanje par primera radi prikaza.\n",
    "def generate_examples(model, input, target):\n",
    "    prediction = model(input)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    display = [input[0], target[0], prediction[0]]\n",
    "    title = [\"Grayscale\", \"Color\", \"Predicted\"]\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "            \n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis(\"off\")\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6abb79-3e07-43fb-b709-3577c11b7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, target in tf.data.Dataset.zip((grayscale_test_set, rgb_test_set)).take(3):\n",
    "    generate_examples(generator, input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6e0c5-f1be-4f12-905b-eb44579383f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95c6d1-651e-40fb-a9b7-4e77473582b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
